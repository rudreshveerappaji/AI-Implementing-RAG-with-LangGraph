# This is an example of how to move the current single agent graph.py RAG implementation to multi-agent system

---

Now we‚Äôre moving from **single-agent RAG workflow** ‚Üí to a **multi-agent graph architecture**.
This is how modern production AI systems are being designed.

Let's

1. Explain the architectural shift
2. Show the new multi-agent design
3. Provide production-ready `graph.py`
4. Explain what changed and why

---

# üß† What Changes in a Multi-Agent Graph?

Previously:

```
Retrieve ‚Üí Grade ‚Üí Generate ‚Üí END
```

Now we introduce specialized agents:

| Agent           | Responsibility            |
| --------------- | ------------------------- |
| Retriever Agent | Fetch documents           |
| Relevance Agent | Evaluate document quality |
| Answer Agent    | Generate answer           |
| Critic Agent    | Verify answer quality     |
| Fallback Agent  | Handle failures           |

Now the workflow becomes:

```
Retriever
    ‚Üì
Relevance Judge
    ‚Üì
(If relevant)
    ‚Üì
Answer Agent
    ‚Üì
Critic Agent
    ‚Üì
(If approved ‚Üí END)
(If rejected ‚Üí Retry Generate)
```

This is now:

* Stateful
* Iterative
* Multi-agent
* Self-correcting

This is closer to how enterprise-grade AI systems work.

---

# üèó Updated State (Important)

First update your `state.py`:

```python
from typing import List, TypedDict
from langchain.schema import Document


class RAGState(TypedDict):
    question: str
    retrieved_docs: List[Document]
    is_relevant: bool
    generation: str
    is_approved: bool
    retry_count: int
```

We added:

* `is_approved`
* `retry_count`

Because now we may loop.

---

# üöÄ Multi-Agent `graph.py`

Here is the upgraded production-style version:

```python
"""
Multi-Agent LangGraph Workflow

Agents:
- Retriever Agent
- Relevance Judge Agent
- Answer Agent
- Critic Agent
- Fallback Agent

Flow:
Retrieve ‚Üí Judge ‚Üí (Generate or Fallback)
Generate ‚Üí Critic ‚Üí (Approve or Retry)
"""

from langgraph.graph import StateGraph, END
from app.state import RAGState
from app.retriever import load_vector_store, retrieve_documents
from app.generator import generate_answer
from app.grader import grade_relevance
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate


# ---------------------------------------------------------
# Dependency Initialization
# ---------------------------------------------------------

vectorstore = load_vector_store()
critic_model = ChatOpenAI(model="gpt-4o-mini", temperature=0)


# ---------------------------------------------------------
# Agent 1: Retriever
# ---------------------------------------------------------

def retriever_agent(state: RAGState):
    docs = retrieve_documents(vectorstore, state["question"])
    return {"retrieved_docs": docs}


# ---------------------------------------------------------
# Agent 2: Relevance Judge
# ---------------------------------------------------------

def relevance_agent(state: RAGState):
    is_relevant = grade_relevance(
        state["question"],
        state["retrieved_docs"]
    )
    return {"is_relevant": is_relevant}


# ---------------------------------------------------------
# Agent 3: Answer Generator
# ---------------------------------------------------------

def answer_agent(state: RAGState):
    answer = generate_answer(
        state["question"],
        state["retrieved_docs"]
    )
    return {"generation": answer}


# ---------------------------------------------------------
# Agent 4: Critic Agent (New)
# ---------------------------------------------------------

def critic_agent(state: RAGState):
    """
    Evaluates whether the generated answer sufficiently
    answers the question using the provided context.
    """

    prompt = ChatPromptTemplate.from_template(
        """
        Question: {question}
        Answer: {generation}

        Is this answer accurate and complete?
        Answer only 'yes' or 'no'.
        """
    )

    chain = prompt | critic_model
    response = chain.invoke({
        "question": state["question"],
        "generation": state["generation"]
    })

    is_approved = "yes" in response.content.lower()

    retry_count = state.get("retry_count", 0)

    return {
        "is_approved": is_approved,
        "retry_count": retry_count + 1
    }


# ---------------------------------------------------------
# Agent 5: Fallback
# ---------------------------------------------------------

def fallback_agent(state: RAGState):
    return {
        "generation": "Sorry, I couldn't find relevant information.",
        "is_approved": True  # End execution
    }


# ---------------------------------------------------------
# Graph Builder
# ---------------------------------------------------------

def build_graph():

    workflow = StateGraph(RAGState)

    # Add agents as nodes
    workflow.add_node("retriever", retriever_agent)
    workflow.add_node("relevance", relevance_agent)
    workflow.add_node("answer", answer_agent)
    workflow.add_node("critic", critic_agent)
    workflow.add_node("fallback", fallback_agent)

    # Entry point
    workflow.set_entry_point("retriever")

    # Retriever ‚Üí Relevance
    workflow.add_edge("retriever", "relevance")

    # Relevance decision
    workflow.add_conditional_edges(
        "relevance",
        lambda state: "answer" if state["is_relevant"] else "fallback",
        {
            "answer": "answer",
            "fallback": "fallback"
        }
    )

    # After answer ‚Üí critic
    workflow.add_edge("answer", "critic")

    # Critic decision
    workflow.add_conditional_edges(
        "critic",
        lambda state: (
            "answer"
            if not state["is_approved"] and state["retry_count"] < 2
            else END
        ),
        {
            "answer": "answer",
            END: END
        }
    )

    # Fallback ‚Üí END
    workflow.add_edge("fallback", END)

    return workflow.compile()
```

---

# üî• What This Upgraded Version Does

## 1Ô∏è‚É£ Adds Agent Specialization

Each agent has a single responsibility.

## 2Ô∏è‚É£ Adds Self-Correction Loop

If critic says:

```
not approved
```

It loops back:

```
answer ‚Üí critic ‚Üí answer
```

Until:

* Approved
* Retry limit reached

That‚Äôs iterative reasoning.

---

# üß† Why This Is Enterprise-Grade

This design:

* Prevents hallucinations
* Allows answer refinement
* Enables future agent expansion
* Mirrors multi-agent LLM research systems

---

# üìä Conceptual Flow

```
Retriever
   ‚Üì
Relevance Judge
   ‚Üì
Answer Agent
   ‚Üì
Critic Agent
   ‚Üì
(Approved?) ‚Üí END
(No?) ‚Üí Retry Answer
```

---

# üèó What You Just Built

This is now:

* A multi-agent orchestration system
* With evaluation
* With retry logic
* With conditional routing
* With state management

This is significantly more advanced than basic RAG.

---

# üöÄ Where This Can Go Next

You can now add:

* Query Rewriter Agent
* Tool-Calling Agent
* Citation Verifier Agent
* Parallel Retrieval Agents
* Multi-hop reasoning agents
* Memory agent
